{"cells":[{"cell_type":"markdown","metadata":{"id":"zIhMP1mu2j7_"},"source":["# Data Import & Cleaning"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":938,"status":"ok","timestamp":1679856578234,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"jadtMnlQ8-jy"},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn import preprocessing as pp\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.compose import make_column_transformer\n","from scipy.stats.mstats import winsorize"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qGiyx6f5MAwE"},"source":["## Data Import "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7565,"status":"ok","timestamp":1679854738473,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"fcJJk_bnL_2o","outputId":"c3a26613-8717-4f1b-bccf-da4f0609768f"},"outputs":[],"source":["## Read data\n","folder = os.path.join(os.getcwd(), \"Data/\")\n","files = os.listdir(folder)\n","\n","data_part1 = pd.read_csv(folder+files[0], delimiter='\\t')\n","data_part2 = pd.read_csv(folder+files[1], delimiter='\\t')\n","data_part3 = pd.read_csv(folder+files[2], delimiter='\\t')\n","data_part4 = pd.read_csv(folder+files[3], delimiter='\\t')\n","\n","data_list = [data_part1, data_part2, data_part3, data_part4]\n","data = pd.concat(data_list)\n","data = data.reset_index(drop=True)\n","data.replace('nan',np.NaN)\n","\n","#data.iloc[109161,:]\n","data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":956},"executionInfo":{"elapsed":290,"status":"ok","timestamp":1679854742264,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"OjrKZkWmnrIb","outputId":"39ffbe61-1648-42bb-ac70-2e257b8d214f"},"outputs":[],"source":["## Handling wrong data\n","\n","# Dropping distorted row (see below)\n","#data = data.drop(208166) # -> make this less static! (TBD) -> Collab\n","data = data.drop(109161) # -> make this less static! (TBD) -> VSCode\n","\n","# Set type of numeric columns that weren't numeric\n","data[\"revol_util\"] = pd.to_numeric(data[\"revol_util\"])\n","data[\"total_acc\"] = pd.to_numeric(data[\"total_acc\"])\n","data[\"mort_acc\"] = pd.to_numeric(data[\"mort_acc\"])\n","\n","# Get states for address\n","data['address'] = data['address'].str[-8:-6]\n","\n","# Get only year for issue_d and earliest_cr_line\n","data['issue_d'] = data['issue_d'].str[4:]\n","data['earliest_cr_line'] = data['earliest_cr_line'].str[4:]\n","\n","# settings to display all columns\n","pd.set_option(\"display.max_columns\", None)\n","\n","# show data\n","data\n","#data.sort_values('open_acc', ascending=False).head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9XfxDeJHqcth"},"source":["Handling of data:\n","*   Index 109161 (VSC) [or 208166 in Collab] distorted data bcs field \"title\" included also \"dti\" and others (mistake in .txt file) -> removed from dataset\n","*   3 columns that should be numeric aren't. Hence datatype made numeric:\n","    *   revol_util\n","    *   total_acc\n","    *   mort_acc\n","*   annual_inc: 1x 0 -> dti 9999 -> how to handle? -> falls probably into outlieer"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0N8f472a22HU"},"source":["## Data Cleaning\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2xgMBErj25I7"},"source":["### Summary Statistics (before)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1679854750010,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"qhug1Xvr2jSX","outputId":"c7fd0009-751e-4f30-a4d7-a849bb225447"},"outputs":[],"source":["# Data length and info\n","n_data = len(data)\n","print(\"Number of data points: \"+str(n_data)+\"\\n\")\n","\n","data.info()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Splitting numerical and categorical variables\n","data_num = data.select_dtypes(include=['float64','int64'])\n","data_cat = data.select_dtypes(include=['object'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Summary for categorical data\n","data_cat.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"elapsed":495,"status":"ok","timestamp":1679854753726,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"8cj5MicIZzXJ","outputId":"73e39bb2-54bb-4e06-c0c1-0618bb663ab9"},"outputs":[],"source":["# Summary for numerical data\n","pd.set_option('display.float_format', lambda x: '%.2f' % x)\n","data_num.describe()\n"]},{"cell_type":"markdown","metadata":{"id":"htFMVFVCgIxC"},"source":["Possible Outliers:\n","*   dti -> income=0, credit_card, charged off\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Count NaN\n","# compute number of NaN values and percentage of NaN values for each column\n","nan_count = data.isna().sum()\n","nan_pct = data.isna().sum()/n_data\n","\n","# create a new dataframe to store the results\n","nans = pd.DataFrame({'nan_count': nan_count, 'nan_pct': nan_pct})\n","nans[\"nan_pct_str\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in nans[\"nan_pct\"]], index = nans.index)\n","nans"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Value count for categorical data\n","vcs = dict()\n","\n","for col in data_cat.columns:\n","    vc = data[col].value_counts().to_frame()\n","    vc[\"pct\"] =  vc[col] / vc[col].sum()\n","    vc[\"pct\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in vc[\"pct\"]], index = vc.index)\n","    vcs[\"vc {0}\".format(col)] = vc\n","    display(vc)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Target Variable**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Change target variable to dummy\n","data['loan_status'] = data['loan_status'].map({'Charged Off': 1, 'Fully Paid': 0})\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Value count loan_status\n","vc_loanstatus = data[\"loan_status\"].value_counts().to_frame()\n","vc_loanstatus[\"pct\"] =  vc_loanstatus[\"loan_status\"] / vc_loanstatus[\"loan_status\"].sum()\n","vc_loanstatus[\"pct\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in vc_loanstatus[\"pct\"]], index = vc_loanstatus.index)\n","display(vc_loanstatus)\n","\n","# Plotting loan_status\n","sns.countplot(x=data[\"loan_status\"], palette = \"Set2\")\n","plt.xticks(rotation=0)\n","plt.show()\n","\n","# Correlation of variables with loan_status\n","cor_target = data.corrwith(data[\"loan_status\"])\n","cor_target.sort_values(axis = 0, ascending = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"msmvL3-O3BWg"},"source":["### Useless & New Variables\n","*   Paper: If train/test split 70/30 -> don’t use variables having >= 30% missing values -> we could do that \n","*   Dropping useless variables: \n","    *  title\n","    * emp_title (maybe?) -> annual_inc might be correlated and more important\n","    * earliest_cr_line\n","    * address\n","* Add/Create variables?\n","    * Macroeconomic information?\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":956},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1679855646205,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"qeVhsGVr3A17","outputId":"2f2b3531-8d50-4156-9cd6-78024853fbf9"},"outputs":[],"source":["# Dropping useless variables\n","data_cleand = data.drop(['title','emp_title', 'earliest_cr_line', 'address'], axis=1)\n","\n","# Dropping variables having more than train_ratio% of nan values\n","train_ratio = 0.7\n","test_ratio = 0.3\n","data_cleand = data_cleand.loc[:, nans[\"nan_pct\"] <= test_ratio]\n","data_cleand\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Splitting numerical and categorical variables\n","data_num_clean = data_cleand.select_dtypes(include=['float64','int64'])\n","data_cat_clean = data_cleand.select_dtypes(include=['object'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data Visualizations \n","* Distribution\n","* Boxplot\n","\n","To visualize outliers and show in presentation\n","-> then outliers removed or winsorized\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Plotting Distribution for non-numeric data (only those that don't have many categories)\n","\n","#dist_nn = [\"term\", \"emp_length\", \"home_ownership\", \"verification_status\", \"loan_status\", \"purpose\", \"initial_list_status\", \"application_type\", \"issue_d\", \"earliest_cr_line\", \"address\"]\n","dist_nn = [\"term\", \"emp_length\", \"home_ownership\", \"verification_status\", \"loan_status\", \"purpose\", \"initial_list_status\", \"application_type\", \"issue_d\"]\n","\n","fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 15), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","\n","for col, ax in zip(dist_nn, axes): \n","    # absolute\n","    sns.countplot(data=data_cleand, x=col, palette = \"Set2\", ax=ax)\n","    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n","\n","fig.delaxes(axes[11])\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Plotting Distribution for non-numeric data (only those that don't have many categories)\n","\n","fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(15, 15), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","\n","for col, ax in zip(dist_nn, axes): \n","    # default vs non-default\n","    sns.countplot(data=data_cleand, x=col, hue=\"loan_status\", palette='Set2', ax=ax)\n","    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n","\n","fig.delaxes(axes[11])    \n","fig.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Plotting Distribution for numeric data\n","\n","fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(15, 7))\n","\n","# loan_amnt -> right/positive skewed\n","sns.histplot(data=data_cleand, x=\"loan_amnt\", binwidth=2000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,0])\n","# int_rate -> right/positive skewed\n","sns.histplot(data=data_cleand, x=\"int_rate\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,1])\n","# installment -> right/positive skewed\n","sns.histplot(data=data_cleand, x=\"installment\", binwidth=50, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,2])\n","# annual_inc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=data_cleand, x=\"annual_inc\", binwidth=10000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,3])\n","# dti -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=data_cleand, x=\"dti\", binwidth=1000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,0])\n","# open_acc -> right/positive skewed\n","sns.histplot(data=data_cleand, x=\"open_acc\", binwidth=2, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,1])\n","# pub_rec -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=data_cleand, x=\"pub_rec\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,2])\n","# revol_bal -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=data_cleand, x=\"revol_bal\", binwidth=10000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,3])\n","# revol_util -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=data_cleand, x=\"revol_util\", binwidth=20, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,0])\n","# total_acc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=data_cleand, x=\"total_acc\", binwidth=5, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,1])\n","# mort_acc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=data_cleand, x=\"mort_acc\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,2])\n","# pub_rec_bankruptcies\n","sns.histplot(data=data_cleand, x=\"pub_rec_bankruptcies\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,3])\n","\n","fig.tight_layout()\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 7), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","cols = data_num_clean.columns[:]\n","\n","for col, ax in zip(cols, axes):\n","    d = data_num_clean \n","    sns.kdeplot(data=d, x=col, shade=True, ax=ax)\n","    ax.set(title=f'Distribution of Variable: {col}', xlabel=None)\n","    \n","#fig.delaxes(axes[8])\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_num_clean.skew()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplot for numeric data\n","\n","fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 7), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","cols = data_num_clean.columns[:]\n","\n","for col, ax in zip(cols, axes):\n","  d = data_num_clean \n","  sns.boxplot(data=d, x=col, orient = \"h\", palette = \"Set2\", width=0.3, whis=[1, 99], ax=ax) # Show the 1st and 99th percentiles\n","  ax.set(title=col, xlabel=None)\n","\n","    \n","#fig.delaxes(axes[8])\n","fig.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mDLOwXxU27-1"},"source":["### Missing and wrong values \n","* Wrong row was already deleted. \n","* Numeric NaN values: Replacing nan values with column means\n","* Non-numeric NaN values: Replacing nan values with category that has highes value count (mode)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1060,"status":"ok","timestamp":1679856371511,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"bnmI3b9JA7gt","outputId":"01877022-60b4-47a1-f0aa-0b7ec0b254df"},"outputs":[],"source":["## Numeric data: Replacing nan values with column means \n","for col in data_cleand.select_dtypes(include=['float64', 'int64']).columns:\n","    data_cleand[col] = data_cleand[col].fillna(data_cleand[col].mean())\n","\n","\n","## Non-Numeric data: Replacing nan values with category that has highes value count? (emp_title, emp_length, title)\n","\n","# loop through each column and replace NaN with mode\n","for col in data_cleand.select_dtypes(include=['object']).columns:\n","        mode = data_cleand[col].mode()[0]                   # get mode of column\n","        data_cleand[col] = data_cleand[col].fillna(mode)    # fill NaN with mode value\n","\n","data_cleand"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":802},"executionInfo":{"elapsed":1792,"status":"ok","timestamp":1679856416835,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"4OAZsSLqPkOC","outputId":"1a4018b3-8741-44d7-dab4-e2c90ae86be9"},"outputs":[],"source":["## Count NaN again\n","# compute number of NaN values and percentage of NaN values for each column\n","nan_count2 = data_cleand.isna().sum()\n","nan_pct2 = data_cleand.isna().sum()/n_data\n","\n","# create a new dataframe to store the results\n","nans2 = pd.DataFrame({'nan_count': nan_count2, 'nan_pct': nan_pct2})\n","nans2[\"nan_pct_str\"] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in nans2[\"nan_pct\"]], index = nans2.index)\n","nans2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["describe2 = data_cleand.describe()\n","describe2.loc['dtype'] = data_cleand.dtypes\n","\n","describe2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Separating numerical and categorical data\n","data_num_final = data_cleand.select_dtypes(include=['float64','int64'])\n","data_cat_final = data_cleand.select_dtypes(include=['object'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"J9L10yDc3GUs"},"source":["### Outliers \n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Outlier Detection:** https://www.freecodecamp.org/news/how-to-detect-outliers-in-machine-learning/ \n","\n","**Outlier Handling:** https://heartbeat.comet.ml/how-to-make-your-machine-learning-models-robust-to-outliers-44d404067d07 \n","\n","* Try out different methods\n","\n","* Delete outliers or winsorize them \\\n","-> Reduces sensitivity of model to outliers "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_num_final.skew()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Winsorization\n","For example, a 90% winsorization sets all observations greater than the 95th percentile equal to the value at the 95th percentile and all observations less than the 5th percentile equal to the value at the 5th percentile. \\\n","-> If no extreme outliers are present, winsorization may be unnecessary \\\n","-> one-sided here?\n","\n","https://towardsdatascience.com/detecting-and-treating-outliers-in-python-part-3-dcb54abaf7b0"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1679854718843,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"6Gfh1_mr3FMT"},"outputs":[],"source":["## Winsorization (if extreme outliers)\n","\n","data_temp = data_cleand\n","data_cleaned_win = data_cleand.copy(deep=True)\n","\n","num_col_list = data_num_final.columns.to_list()\n","num_col_list.remove(\"loan_status\")\n","\n","\n","# Winsorize on right-tail\n","for col in num_col_list:\n","    data_cleaned_win[col] = winsorize(data_temp[col], limits=(0, 0.01))\n","\n","data_cleaned_win.describe()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_cleaned_win.skew()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Plotting Distribution for numeric data\n","\n","fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(15, 7))\n","\n","d = data_cleaned_win\n","\n","# loan_amnt -> right/positive skewed\n","sns.histplot(data=d, x=\"loan_amnt\", binwidth=1000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,0])\n","# int_rate -> right/positive skewed\n","sns.histplot(data=d, x=\"int_rate\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,1])\n","# installment -> right/positive skewed\n","sns.histplot(data=d, x=\"installment\", binwidth=50, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,2])\n","# annual_inc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"annual_inc\", binwidth=10000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,3])\n","# dti -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"dti\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,0])\n","# open_acc -> right/positive skewed\n","sns.histplot(data=d, x=\"open_acc\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,1])\n","# pub_rec -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"pub_rec\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,2])\n","# revol_bal -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"revol_bal\", binwidth=2000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,3])\n","# revol_util -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"revol_util\", binwidth=2, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,0])\n","# total_acc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"total_acc\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,1])\n","# mort_acc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"mort_acc\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,2])\n","# pub_rec_bankruptcies\n","sns.histplot(data=d, x=\"pub_rec_bankruptcies\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,3])\n","\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 7), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","cols = data_cleaned_win.select_dtypes(include=['float64', 'int64']).columns[:]\n","\n","for col, ax in zip(cols, axes):\n","    d = data_cleaned_win.select_dtypes(include=['float64', 'int64'])\n","    sns.kdeplot(data=d, x=col, shade=True, ax=ax)\n","    ax.set(title=f'Distribution of Variable: {col}', xlabel=None)\n","    \n","#fig.delaxes(axes[8])\n","fig.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Log-Scale Transformation to detect outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Log-Scale Transformation (often preferred when the response variable follows exponential distribution or is right-skewed)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### Outlier Removal"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Using the Interquartile Range (IQR)**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get numerical variable names\n","num_col_list = data_num_final.columns.to_list()\n","num_col_list.remove(\"loan_status\")\n","num_col_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_cleaned_iqr = data_cleand\n","\n","upper_limits_iqr = {}\n","lower_limits_iqr = {}\n","\n","for col in num_col_list:\n","\n","    print(\"\\n\", col, \":\")\n","\n","    percentile_25 = data_cleand[col].quantile(0.25)\n","    percentile_75 = data_cleand[col].quantile(0.75)\n","\n","    print(\"25 percentile: \", percentile_25)\n","    print(\"75 percentile: \", percentile_75)  \n","\n","    iqr = percentile_75 - percentile_25\n","    print(\"IQR: \", iqr)\n","\n","    upper_limit = percentile_75 + 1.5 * iqr\n","    lower_limit = percentile_25 - 1.5 * iqr\n","\n","    upper_limits_iqr[col] = upper_limit\n","    lower_limits_iqr[col] = lower_limit\n","\n","    print(\"Upper limit: \", upper_limit)   \n","    print(\"Lower limit: \", lower_limit)\n","\n","for col in num_col_list:  \n","    #data_test_iqr = data_test_iqr[(data_test_iqr[col] > lower_limits_iqr[col]) & (data_test_iqr[col] < upper_limits_iqr[col])]\n","    data_cleaned_iqr = data_cleaned_iqr[(data_cleaned_iqr[col] < upper_limits_iqr[col])]\n","\n","print(\"\\n\")\n","print(\"Old Shape: \", data_cleand.shape)\n","print(\"New Shape: \", data_cleaned_iqr.shape)\n","\n","diff = len(data_cleand) - len(data_cleaned_iqr)\n","print(\"Size difference: \", diff)\n","data_cleaned_iqr\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplot for numeric data\n","\n","fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 15), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","cols = data_cleaned_iqr.select_dtypes(include=['float64', 'int64']).columns[:]\n","\n","for col, ax in zip(cols, axes):\n","  d = data_cleaned_iqr.select_dtypes(include=['float64', 'int64'])\n","  #sns.boxplot(data=d, x=col, orient = \"h\", palette = \"Set2\", width=0.3, whis=[1, 99], ax=ax)\n","  sns.boxplot(data=d, x=col, orient = \"h\", palette = \"Set2\", width=0.3, ax=ax)\n","  ax.set(title=col, xlabel=None)\n","\n","    \n","#fig.delaxes(axes[8])\n","fig.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**Using Percentile** \\\n","Better for all together or single variables?\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_cleaned_per = data_cleand\n","\n","upper_limits_per = {}\n","lower_limits_per = {}\n","\n","for col in num_col_list:\n","\n","    print(\"\\n\", col, \":\")\n","\n","    upper_bound = data_cleand[col].quantile(0.99)  \n","    lower_bound = data_cleand[col].quantile(0.01)  \n","\n","    print(\"99 percentile: \", upper_bound)\n","    print(\"01 percentile: \", lower_bound)  \n","\n","    upper_limits_per[col] = upper_bound\n","    lower_limits_per[col] = lower_bound\n","\n","for col in num_col_list:  \n","    #data_test_per = data_test_per[(data_test_per[col] > lower_limits_per[col]) & (data_test_per[col] < upper_limits_per[col])]\n","    data_cleaned_per = data_cleaned_per[(data_cleaned_per[col] < upper_limits_per[col])]\n","\n","print(\"\\n\")\n","print(\"Old Shape: \", data_cleand.shape)\n","print(\"New Shape: \", data_cleaned_per.shape)\n","\n","diff = len(data_cleand) - len(data_cleaned_per)\n","print(\"Size difference: \", diff)\n","data_cleaned_per"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplot for numeric data\n","\n","fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 15), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","cols = data_cleaned_per.select_dtypes(include=['float64', 'int64']).columns[:]\n","\n","for col, ax in zip(cols, axes):\n","  d = data_cleaned_per.select_dtypes(include=['float64', 'int64'])\n","  sns.boxplot(data=d, x=col, orient = \"h\", palette = \"Set2\", width=0.3, whis=[1, 99], ax=ax)\n","  ax.set(title=col, xlabel=None)\n","\n","    \n","#fig.delaxes(axes[8])\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(15, 7), sharex = False, sharey = False)\n","axes = axes.ravel()  \n","cols = data_cleaned_per.select_dtypes(include=['float64', 'int64']).columns[:]\n","\n","for col, ax in zip(cols, axes):\n","    d = data_cleaned_per.select_dtypes(include=['float64', 'int64'])\n","    sns.kdeplot(data=d, x=col, shade=True, ax=ax)\n","    ax.set(title=f'Distribution of Variable: {col}', xlabel=None)\n","    \n","#fig.delaxes(axes[8])\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Plotting Distribution for numeric data\n","\n","fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(15, 7))\n","\n","d = data_cleaned_per\n","\n","# loan_amnt -> right/positive skewed\n","sns.histplot(data=d, x=\"loan_amnt\", binwidth=1000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,0])\n","# int_rate -> right/positive skewed\n","sns.histplot(data=d, x=\"int_rate\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,1])\n","# installment -> right/positive skewed\n","sns.histplot(data=d, x=\"installment\", binwidth=50, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,2])\n","# annual_inc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"annual_inc\", binwidth=10000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[0,3])\n","# dti -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"dti\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,0])\n","# open_acc -> right/positive skewed\n","sns.histplot(data=d, x=\"open_acc\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,1])\n","# pub_rec -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"pub_rec\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,2])\n","# revol_bal -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"revol_bal\", binwidth=2000, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[1,3])\n","# revol_util -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"revol_util\", binwidth=2, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,0])\n","# total_acc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"total_acc\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,1])\n","# mort_acc -> right/positive skewed -> outlier -> re-do without\n","sns.histplot(data=d, x=\"mort_acc\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,2])\n","# pub_rec_bankruptcies\n","sns.histplot(data=d, x=\"pub_rec_bankruptcies\", binwidth=1, color=\"darkblue\", kde=True, kde_kws={'bw_method': 0.4}, ax=axs[2,3])\n","\n","fig.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Dealing with Categorical Data \n","Create Dummies for categorical Data. \\\n","-> OneHotEncoding: https://towardsdatascience.com/an-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee\n","\n","Problem with OHE because of:\n","* earliest_cr_line \n","* address \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["OneHotEncoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_cleand = data_cleaned_win      # winsorized data\n","# data_cleand = data_cleaned_per    # outliers removed 1%-99%-percentiles\n","# data_cleand = data_cleaned_iqr    # outliers removed with 25%-75%-IQR\n","# data_cleand = data_cleand         # data with outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_cleand.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Separating numerical and categorical data\n","data_num_final = data_cleand.select_dtypes(include=['float64','int64'])\n","data_cat_final = data_cleand.select_dtypes(include=['object'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Categorical columns positions\n","cat_cols = data_cat_final.columns\n","cat_cols_list = cat_cols.to_list()\n","cat_col_positions = [data_cleand.columns.get_loc(col) for col in cat_cols]\n","display(cat_col_positions)\n","display(cat_cols_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# OneHotEncoding categorical columns\n","ct = ColumnTransformer(\n","    [('ohe', pp.OneHotEncoder(sparse=False), cat_col_positions),],  # the column numbers I want to apply this to\n","    remainder='passthrough'  # This leaves the rest of my columns in place\n",")\n","ct_transformed = ct.fit_transform(data_cleand)\n","data_final = pd.DataFrame(ct_transformed, columns=ct.get_feature_names_out()) # putting array in a dataframe using column names\n","data_final"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_3NPjVP_3H7X"},"source":["### Data Normalization\n","Standardization, Normalization or Binning approach"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1679854718843,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"Ss3nEPht3KlE"},"outputs":[],"source":["# Should work once categorical variables one-hot-encoded\n","\n","scaler = MinMaxScaler()\n","scaler.fit(data_final)\n","scaled = scaler.fit_transform(data_final)\n","data_final_scaled = pd.DataFrame(scaled, columns=data_final.columns)\n","data_final_scaled"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_cols = [col for col in data_final_scaled.columns if 'remainder' in col]\n","cat_cols = [col for col in data_final_scaled.columns if 'remainder' not in col]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data Standardization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler_std = StandardScaler()\n","\n","standardized_data = scaler_std.fit_transform(data_final_scaled)\n","\n","data_final_scaled_std = pd.DataFrame(standardized_data, columns=data_final.columns)\n","data_final_scaled_std"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Final datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data_final            -> not normalized, not standardized\n","# data_final_scaled     -> normalized\n","# data_final_scaled_std -> normalized, standardized"]},{"cell_type":"markdown","metadata":{"id":"iuypVRxI4nbX"},"source":["### Summary Statistics (final)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":40,"status":"aborted","timestamp":1679854718843,"user":{"displayName":"Lorena Tassone","userId":"09870923884693769595"},"user_tz":-120},"id":"Bd0XypYe4r4D"},"outputs":[],"source":["data_final_scaled.describe()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"r7HmdziSQABP"},"source":["### Data Visualizations (final)\n","Final of used factors \\\n","(for ppt)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sns.pairplot(data_cleand, hue=\"loan_status\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XlZmuklF_dJp"},"source":["## Correlation Analysis Variables\n","Find and drop highly correlated variables"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create correlation matrix\n","corr_matrix = data_final_scaled.corr().abs()\n","\n","# Select upper triangle of correlation matrix\n","upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n","\n","# Find features with correlation greater than 0.8\n","to_drop = [column for column in upper.columns if any(upper[column] > 0.8)] # >= 0.8 -> 5\n","display(to_drop)\n","\n","# Drop features \n","data_final_scaled = data_final_scaled.drop(to_drop, axis=1, inplace=False)\n","data_final_scaled"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# highest correlated pairs\n","# corr_matrix_unstacked = corr_matrix.unstack()\n","# sorted = corr_matrix_unstacked.sort_values(kind=\"quicksort\")\n","# display(sorted)\n","\n","# sorted_df = pd.DataFrame(sorted)\n","\n","# display(sorted_df.loc[(sorted_df[0] >= 0.8)])\n","# display(sorted_df.loc[(sorted_df[0] <= -0.8)])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["It calculates the correlation/strength-of-association of features in the data-set with both categorical and continuous features using: Pearson’s R for continuous-continuous cases, Correlation Ratio for categorical-continuous cases, Cramer’s V or Theil’s U for categorical-categorical cases.\n","associations function returns a dictionary that contains:\n","\n","* ‘corr’ as key : A DataFrame of the correlation between all features.\n","* ‘ax’ as value: A matplotlib axe which contains the correlation heatmap."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from dython.nominal import associations\n","\n","# # associations(dataset, nominal_columns='auto', numerical_columns=None, mark_columns=False, nom_nom_assoc='cramer', num_num_assoc='pearson', \n","# #              bias_correction=True, nan_strategy=_REPLACE, nan_replace_value=_DEFAULT_REPLACE_VALUE, ax=None, figsize=None, annot=True, fmt='.2f', \n","# #              cmap=None, sv_color='silver', cbar=True, vmax=1.0, vmin=None, plot=True, compute_only=False, clustering=False, title=None, filename=None)\n","\n","# complete_correlation = associations(data_final_scaled, figsize=(10,10))\n","\n","# df_complete_corr = complete_correlation['corr']\n","# df_complete_corr.dropna(axis=1, how='all').dropna(axis=0, how='all').style.background_gradient(cmap='coolwarm', axis=None).set_precision(2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Correlation Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# only numeric variables (before normalization)\n","plt.figure(figsize=(10,10))\n","sns.heatmap(data_num_final.astype(float).corr(),linewidths=0.1,vmax=1.0, \n","            square=True,  linecolor='white', annot=True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# numerical columns positions in final dataset\n","num_cols = [col for col in data_final_scaled.columns if 'remainder' in col]\n","num_cols"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# only numeric variables (after normalization -> same as before)\n","plt.figure(figsize=(10,10))\n","sns.heatmap(data_final_scaled[num_cols].astype(float).corr(),linewidths=0.1,vmax=1.0, \n","            square=True,  linecolor='white', annot=True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(30,30))\n","sns.heatmap(data_final_scaled.astype(float).corr(),linewidths=0.1,vmax=1.0, \n","            square=True,  linecolor='white', annot=True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data_final_scaled"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data reality check of most important features\n","* loan_amnt\n","*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP32X2JymOn3ee3SDK/ExAe","collapsed_sections":["rFOAP1Bt2xU3"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"f03ef0067a66508812d38afdaafb3edbfd26e3dd773f73c9bd0790861b814585"}}},"nbformat":4,"nbformat_minor":0}
